import tensorflow as tf
import numpy as np
a=tf.constant(15)
b=tf.constant(20)
print(a*b)
tf.Tensor(300, shape=(), dtype=int32)
x=np.random.rand(100).astype(np.float32)
print(x)

y=0.2*x+0.2
W=tf.Variable(tf.random.normal([1]))
b=tf.Variable(tf.zeros([1]))
def mse_loss():
    y_pred=W*x+b
    loss=tf.reduce_mean(tf.square(y_pred-y))
    return loss
optimizer=tf.optimizers.Adam()
for step in range(5000):
    optimizer.minimize(mse_loss, var_list=[W,b])
    if step%500==0:
        print(step, W.numpy(),b.numpy())

# KERAS

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential
data = pd.read_csv(r"E:\DL\Deep Learning Datasets\2 Diabetes\diabetes.csv")
data.head()

x = data.drop('Outcome',axis=1).values
y = data['Outcome'].values
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.fit_transform(x_test)
model = Sequential([
    Dense(64,activation='relu',input_shape=(x_train.shape[1],)),
    Dense(32,activation='relu'),
    Dense(1,activation='sigmoid')
])
 
model.compile(
    loss = 'binary_crossentropy',
    optimizer = Adam(),
    metrics = ['accuracy']
)
history = model.fit(
    x_train,
    y_train,
    epochs = 50,
    batch_size = 16,
    validation_split = 0.2
)


test_loss, test_acc = model.evaluate(x_test, y_test)
print("Test Loss: ",test_loss)
print("Test Accuracy: ",test_acc)
 
print("First 5 Predictions:\n")
predictions = model.predict(x_test)
n = 5
for i in range(n):
    if (predictions[i] > 0.5):
        prediction = 'Diabetic'
    else:
        prediction = 'Non-Diabetic'
    print(f"Prediction {i+1}: {prediction}\n")

model.summary()
